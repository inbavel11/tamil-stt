{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNJI2BeuiXqUgWvkonzHj0j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import soundfile as sf\n","import torch\n","import torchaudio\n","from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n","\n","def parse_transcription(wav_file):\n","    # load pretrained model\n","    processor = Wav2Vec2Processor.from_pretrained(\"addy88/wav2vec2-tamil-stt\")\n","    model = Wav2Vec2ForCTC.from_pretrained(\"addy88/wav2vec2-tamil-stt\")\n","\n","    # load audio\n","    audio_input, sample_rate = sf.read(wav_file)\n","\n","    # Resample to 16000 Hz if needed\n","    if sample_rate != 16000:\n","        print(f\"Resampling from {sample_rate} Hz to 16000 Hz\")\n","        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n","        audio_input = resampler(torch.tensor(audio_input).float()).numpy()\n","\n","    # Convert audio input to correct format and pass 16000 Hz as the sample rate\n","    input_values = processor(audio_input, sampling_rate=16000, return_tensors=\"pt\").input_values\n","\n","    # INFERENCE\n","    logits = model(input_values).logits\n","    predicted_ids = torch.argmax(logits, dim=-1)\n","\n","    # Transcribe\n","    transcription = processor.decode(predicted_ids[0], skip_special_tokens=True)\n","    print(transcription)\n","\n","# Example usage\n","parse_transcription('/content/ta_in_male/tag_00023_00002135809.wav')\n"],"metadata":{"id":"IKzyCjoV5ySg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725871911415,"user_tz":-480,"elapsed":3571,"user":{"displayName":"INBAVEL S","userId":"01930885020195414268"}},"outputId":"1d19b178-4992-4f32-b3bf-d0d49ef6d785"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at addy88/wav2vec2-tamil-stt were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n","- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at addy88/wav2vec2-tamil-stt and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Resampling from 48000 Hz to 16000 Hz\n","செப்டம்பர் ஐந்து ஆசிரியர் தினம்\n"]}]},{"cell_type":"code","source":["import torch\n","from transformers import Wav2Vec2ForCTC\n","\n","model = Wav2Vec2ForCTC.from_pretrained(\"addy88/wav2vec2-tamil-stt\")\n","model.eval()\n","\n","# Save the model directly as a PyTorch model\n","torch.save(model.state_dict(), \"wav2vec2_tamil_stt.pt\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bEt5_7iF6Ri0","executionInfo":{"status":"ok","timestamp":1725872228240,"user_tz":-480,"elapsed":7043,"user":{"displayName":"INBAVEL S","userId":"01930885020195414268"}},"outputId":"08a9d9a8-9fee-4f86-c0de-823ea2a1edfe"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at addy88/wav2vec2-tamil-stt were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n","- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at addy88/wav2vec2-tamil-stt and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"lm3Wpb8fAl-3","executionInfo":{"status":"ok","timestamp":1725872459275,"user_tz":-480,"elapsed":1321,"user":{"displayName":"INBAVEL S","userId":"01930885020195414268"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"a6k0Z7Eq-ACX","executionInfo":{"status":"ok","timestamp":1725872462680,"user_tz":-480,"elapsed":4,"user":{"displayName":"INBAVEL S","userId":"01930885020195414268"}}},"execution_count":18,"outputs":[]}]}